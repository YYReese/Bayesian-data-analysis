---
editor_options:
  markdown:
    wrap: 72
output: pdf_document
---

**University of Edinburgh**

**School of Mathematics**

**Bayesian Data Analysis, 2022/2023, Semester 2**

**Assignment 1**

```{r}
rm(list = ls(all = TRUE))
#Do not delete this!
#It clears all variables to ensure reproducibility
library(dbplyr)
library(tidyverse)
library(rjags)
library(INLA)
library(dummies)
library(Matrix)
```

![](Exchange-rate.jpg)

**Problem 1**

**In this problem, we study a dataset about currency exchange rates. The
exrates dataset of the stochvol package contains the daily average
exchange rates of 24 currencies versus the EUR, from 2000-01-03 until
2012-04-04.**

```{r}
set.seed(1234)
require(stochvol)
data("exrates")

#The first 6 rows of the dataframe
print.data.frame(exrates[1:6,])

cat(paste("Data from ", min(exrates$date)," until ",max(exrates$date)))
```

**As we can see, not all dates are included in the dataset. Some are
missing, such as weekends, and public holidays.**

**In this problem, we are going to fit a various stochastic volatility
models on this dataset (see e.g.
<https://www.jstor.org/stable/1392251>).**

**a)[10 marks] Consider the following leveraged Stochastic Volatility
(SV) model.**

$\begin{aligned} y_t&=\beta_0+\beta_1 y_{t-1}+\exp(h_t/2)\epsilon_t \quad \text{for}\quad 1\le t\le T,\\ h_{t+1}&=\mu+\phi(h_t-\mu)+\sigma \eta_t\quad \text{for} \quad 0\le t\le T, \quad h_0\sim N(\mu, \sigma^2/(1-\phi^2)),\\(\epsilon_t,\eta_t)&\sim N\left(0, \Sigma_{\rho}\right)\quad \text{ for } \quad \Sigma_{\rho}=\left(\begin{matrix}1 & \rho\\ \rho & 1\end{matrix}\right). \end{aligned}$

**Here** $t$ **is the time index,** $y_t$ **are the observations (such
as daily USD/EUR rate),** $h_t$ **are the log-variance process,**
$\epsilon_t$ **is the observation noise, and** $\eta_t$ **is the
log-variance process noise (which are correlated, but independent for
different values of** \$t\$**). The hyperparameters are**
$\beta_0, \beta_1, \mu, \phi, \sigma, \rho$**.**

**For stability, it is necessary to have** $\phi\in (-1,1)$**, and by
the definition of correlation matrices, we have** $\rho\in [-1,1]$**.**

**Implement this model in JAGS or Stan on the first 3 months of USD/EUR
data from the dataset, i.e. from dates 2000-01-03 until 2000-04-02.**

**Explain how did you choose priors for all parameters. Explain how did
you take into account the days without observation in your model.**

**Fit the model, do convergence diagnostics, print out the summary of
the results, and discuss them.**

**Make sure that the Effective Sample Size is at least 1000 for all 6
hyperparameters (you need to choose burn-in and number of steps
appropriately for this).**

## Data exploration

First, we extract the first 3 months of USD/EUR data from the dataset,
and insert new entries to where the data is missing with NA in order to
include all dates from 2000-01-03 until 2000-04-02. Then we create a
response variable y by storing the logarithm of the USD/EUR exchange
rate estimate for each day, with NA if they are missing. One of the advantages of taking the logarithm is that it makes the response variable lives on the whole real line instead of sorely positive real line (as the exchange rate cannot be zero or negative). 

Below is the plot of the response variable y we just created. We see there is a decreasing trend with some local fluctuations.

```{r}
# Create data input for JAGS
eur2usd <- exrates %>% 
  filter(date <= "2000/04/02") %>%
  mutate(date=as.numeric(date)) %>%
  select(USD,date) %>%
  mutate(date=date-date[1]+1,USD=log(USD))
# Add 5 more NA nodes at the end to include 04-01 to 04-05 
# for future work i.e.(c)(e)
n <- eur2usd$date[length(eur2usd$date)] + 5 
y <- rep(NA,n)
j <- 1
for(i in eur2usd$date){
  y[i] <- eur2usd$USD[j]
  j <- j+1
}
#y <- y-mean(y,na.rm = TRUE)
plot(y)
```

## Leverage Stochastic Volatility model

Let $\boldsymbol{\theta}$ denote the parameter set,
$\boldsymbol{\theta}=\{\beta_0, \beta_1, \phi,\rho,\sigma\}$. Since
$\epsilon_t$ and $\eta_t$ given $\boldsymbol{\theta}$ are jointly
Gaussian, $y_t$ and $h_{t+1}$ given $h_t$ and $\boldsymbol{\theta}$ are
also jointly Gaussian with mean and covariance matrix given below due to
the linearity. 
$$
\left[\begin{matrix} y_t \\ h_{t+1} \end{matrix}\right]\bigg|_{h_t,y_{t-1},\boldsymbol{\theta}} \sim \mathcal{N} \left( \left[ \begin{matrix} \beta_0+\beta_1y_{t-1} \\ mu+\phi(h_t-\mu) \end{matrix} \right] , \left[ \begin{matrix} \exp(h_t) & \sigma \rho \exp(\frac{h_t}{2})\\\sigma \rho \exp(\frac{h_t}{2})& \sigma^2 \end{matrix} \right] \right)
$$ 
By conditioning, the leverage stochastic volatility model can be rewritten as 
$$ h_{t+1} | \boldsymbol{\theta} \sim \mathcal{N}(\mu+\phi(h_t-\mu),\sigma^2)$$

$$
y_t|h_{t+1},h_{t},y_{t-1},\boldsymbol{\theta} \sim
\mathcal{N}
\left(\beta_0+\beta_1y_{t-1}+\exp\left(\frac{h_t}{2}\right)(h_{t+1}-\mu-\phi(h_t-\mu)),(1-\rho^2)\exp\left(h_t\right)\right)
$$

## Prior specification 

$\beta_0,\beta_1$: For coefficients $\beta_0$ and $\beta_1$, it is natural to set the Normal prior on them. As we do not have much prior belief, large variances are suggested. $\beta_0 \sim \mathcal{N}(0,1000)$. $\beta_1 \sim \mathcal{N}(0,1000)$.

$\mu$: A vague Normal prior with mean $0$ and large variance (e.g.$1000$) is used for $\mu$. $\mu \sim \mathcal {N} (0,1000)$.

$\phi$: As it is necessary to have $\phi \in (-1,1)$ for stability, a prior that ranges from $-1$ to $1$ is needed. A Beta prior has been widely used for parameters ranging from $0$ to $1$. If we put a Beta prior on $\frac{\phi+1}{2}$, we then have $0<\frac{\phi+1}{2}<1$. Consequently, $-1<\phi<1$ is ensured. Therefore, the prior for $\phi$ is chosen to be $\frac{\phi+1}{2} \sim \text{Beta} (1,1)$.

$\sigma$: $\sigma \sim \text{Gamma} (0, 1000)$

$\rho$: An uninformative prior is used for $\rho$. In particular sine
$\rho\in [-1,1]$, we use $\rho \sim \text{Uniform} (-1,1)$.

We have implemented the model in JAGS as shown below. The hidden states are stored in the vector $h$, and the observations are stored in the vector $y$. We pass along $y$ created above to JAGS as $y$ when compiling the model. In this $y$ variable (which is a vector of length $n$), remember that we have already set all the points with missing data as NA. JAGS is able to handle these NA values automatically by creating stochastic nodes for them. We ran $5$ chains with $50000$ samples after $50000$ burn-in iterations, starting from an initial position for $y$ based on the true observation of $y_1$ and some random noise. We use the initial values set by default in JAGS.

```{r}
#model in BUGS syntax

model1_string <- "model {
  # prior
  beta0 ~ dnorm(beta.mu.0, beta.tau.0)
  beta1 ~ dnorm(beta.mu.1, beta.tau.1)
  mu ~ dnorm(mu.mu,mu.tau)
  trans_phi ~ dbeta(20,1.5)
  phi <- 2*trans_phi-1
  tau ~ dgamma(sigma.a,sigma.b) 
  sigma <- pow(tau,-1/2)
  trans_rho ~ dbeta(3,5)
  rho <- 2*trans_rho-1
  # Likelihood
  h[1] ~ dnorm(mu, (1-phi^2)*tau)
  #The evolution of the hidden states x according to the model
  for(i in 2:(n+1)) {
    h[i] ~ dnorm(mu+phi*(h[i-1]-mu), tau) 
  }
  
  y[1] ~ dnorm(mean.y0,prec.y0)
  y_rep[1] ~ dnorm(mean.y0,prec.y0)
  y.var[1] <- prec.y0^(-1)
  for(i in 2:n) {
    y.mu[i] <- rho/sigma*exp(h[i]/2)*(h[i+1]-mu-phi*(h[i]-mu))+beta0 + beta1*y[i-1]
    y.var[i] <- exp(h[i])*(1-rho^2) 
    y[i] ~ dnorm(y.mu[i], pow(y.var[i],-1))
    y_rep[i] ~ dnorm(y.mu[i],pow(y.var[i],-1))
  }
  


}"
```

```{r}
# Create data input for JAGS
eur2usd.data <- list(n=n-3,y=y,mean.y0=y[1],prec.y0=1,
                     beta.mu.0=0,beta.tau.0=0.001,
                     beta.mu.1=0,beta.tau.1=0.001,
                     mu.mu=0,mu.tau=0.001,sigma.a=1,sigma.b=1)
```

```{r}
num.chains <- 5
# Compile and run the model
model1 <- jags.model(file=textConnection(model1_string), 
                        data=eur2usd.data,
                        n.chains=num.chains)
# Burnin for 50000 samples
update(model1,50000)
```

We printed out the posterior summaries for the model parameters beta0, beta1, mu, phi, rho, and sigma using the `summary(res.model1)` command. We can see that the standard deviations are relatively smaller than the means in absolute value, indicating that the the amount of data is sufficient to fit the model parameters with some degree of confidence. The time series SE is smaller than the posterior means (in absolute value), showing that our estimates are relatively accurate. From the trace plots, we see that the five chains had overlapped with each other and mixing well, providing no evidence of divergence. 

```{r}
# Running the model, monitoring the variable theta
res.model1=coda.samples(model1,variable.names=c("beta0", "beta1", "mu", "phi", "sigma", "rho"), n.iter=50000)

#Setting margins to be small
summary(res.model1);
plot(res.model1)
```

We plotted the autocorrelation functions for all six hyperparameters using the `acf` function. We set the `lag.max` parameter to $1000$ to clearly display the plots. We can see that the samples suffer from more autocorrelation at first. However, the autocorrelations decrease as the lag increases, and they are almost gone after a lag of $500$. 

```{r}
par(mfrow = c(3,2))
acf(res.model1[[1]][,"beta0"],lag.max=1000,main="ACF for beta0")
acf(res.model1[[1]][,"beta1"],lag.max=1000,main="ACF for beta1")
acf(res.model1[[1]][,"mu"],lag.max=1000,main="ACF for mu")
acf(res.model1[[1]][,"phi"],lag.max=1000,main="ACF for phi")
acf(res.model1[[1]][,"rho"],lag.max=1000,main="ACF for rho")
acf(res.model1[[1]][,"sigma"],lag.max=1000,main="ACF for sigma")
```

Below is the report of the effective sample size of each hyperparameters. With $50000$ burnin and $5000$ samples for $5$ chains, each of the parameters has ESS greater than $1000$. However, since the burnin and sample size are both large (50000) which is much greater than the ESSs, this again indicates the samples were much correlated at the first few iterations. Nevertheless, there are at least over $1000$ independent MCMC samples which is considered enough for posterior inference.

```{r}
effectiveSize(res.model1);
```

Based on the MCMC samples, we compute plot the Gelman-Rubin convergence as below. As we can see from the plots, the Gelman-Rubin diagnostics values are very close to $1$ for each of the parameters, indicating that we have approximated the stationary distribution well. 
```{r}
gelman.plot(res.model1)
```
Overall, the model has passed all the above convergence diagnostics and thus we can use the samples to do posterior inference.


**b)[10 marks] In practice, one often encounters outliers in exchange
rates. These can be sometimes modeled by assuming Student's t
distribution in the observation errors (i.e.** $\epsilon_t$). **The
robust leveraged SV model can be expressed as**

$\begin{aligned} y_t&=\beta_0+\beta_1 y_{t-1}+\exp(h_t/2)\epsilon_t \quad \text{for}\quad 1\le t\le T,\\ h_{t+1}&=\mu+\phi(h_t-\mu)+\sigma \eta_t\quad \text{for} \quad 0\le t\le T, \quad h_0\sim N(\mu, \sigma^2/(1-\phi^2)),\\ \eta_t&\sim N(0,1)\\ \epsilon_t|\eta_t&\sim t_{\nu}(\rho \eta_t ,1). \end{aligned}$

**Here** $\nu$ **is the degrees of freedom parameter (unknown).**

**Implement this model in JAGS or Stan on the first 3 months of USD/EUR
data from the dataset.**

**Explain how did you choose priors for all parameters. Explain how did
you take into account the days without observation in your model.**

**Fit the model, do convergence diagnostics, print out the summary of
the results, and discuss them.**

**Make sure that the Effective Sample Size is at least 1000 for all 6
hyperparameters (you need to choose burn-in and number of steps
appropriately for this).**

In general, a non-standard Student's t random variable $X$ can be written as a linear transformation of a standard one : $X=\mu+\sigma X_{standard}$ where $X_{standard}=\frac{Z}{\sqrt{\mathcal{X}_n^2/n}}$ with $Z\sim \mathcal{N}(0,1)$ and $\mathcal{X}_n^2/n \sim \text{Gamma}(\frac \nu 2, \frac \nu 2)$. Denote $X\sim t_\nu(\mu, \sigma^2)$. Then, given $\eta_t$, $\epsilon_t|\eta_t$ is a non-standard Student's t random variable which can be written as $\epsilon_t = \rho\eta_t+\frac{Z}{\sqrt{G}}$ with $Z\sim \mathcal{N}(0,1)$ and $G\sim \text{Gamma}(\frac \nu 2 , \frac \nu 2)$. Given $h_t, y_{t-1}$ and all the values of hyperparameteres, $y_t$ can be written as 
$$
\begin{align}
y_t &= \beta_0+\beta_1y_{t-1}+\exp\left(\frac{h_t}{2}\right)\left(\rho\eta_t+\frac{Z}{\sqrt{G}}\right)\\
&= \beta_0+\beta_1y_{y-1}+ \exp\left(\frac{h_t}{2}\right)\rho\eta_t+\exp\left(\frac{h_t}{2}\right)\frac{Z}{\sqrt{G}}\right) \\
\end{align}
$$
Recognise that $y_t$ is again a student's t random variable  $$y_t|y_{t-1},h_{t},\eta_t,\boldsymbol{\theta} \sim t_\nu\left(\beta_0+\beta_1y_{y-1}+ \exp\left(\frac{h_t}{2}\right)\rho\eta_t, \exp(h_t)\right).$$
Hence, the above model can be rewritten as follows.
$$
\begin{align}
\eta_t &\sim \mathcal{N}(0,1)\\
h_{t+1}|h_{t-1},\boldsymbol{\theta} &\sim \mathcal{N}(\mu+\phi(h_t-\mu),\sigma^2)\\
y_t|y_{t-1},h_{t},\eta_t,\boldsymbol{\theta} & \sim \mathcal{N} \left(\beta_0+\beta_1y_{t-1}+\exp\left(\frac{h_t}{2}\right)\rho\eta_t, \exp(h_t)\right)\\
\end{align}
$$

We follow the same strategy to choose priors for $\beta_0,\beta_1, \mu,\phi,\sigma$ and $\rho$. See the explanations for part (a) for details of the choices for these parameters. For the hyperparameter $\nu$, we put a Chi-square distribution as its prior.

```{r}
#model in BUGS syntax 
model2_string <- "model {
  # prior
  beta0 ~ dnorm(beta.mu.0, beta.tau.0)
  beta1 ~ dnorm(beta.mu.1, beta.tau.1)
  mu ~ dnorm(mu.mu,mu.tau)
  trans_phi ~ dbeta(18,1.5)
  phi <- 2*trans_phi-1
  tau ~ dgamma(sigma.a,sigma.b)
  sigma <- pow(tau,-2)
  trans_rho ~ dbeta(3,5)
  rho <- 2*trans_rho-1
  k ~ dchisq(8) 
  
  # Likelihood
  h[1] ~ dnorm(mu, (1-phi^2)*tau)
  #The evolution of the hidden states x according to the model
  for(i in 2:(n+1)) {
    eta[i] ~ dnorm(0,1)
    h[i] ~ dnorm(mu+phi*(h[i-1]-mu), tau)
  }
  
  y.mu[1] <- mean.y0
  y.tau[1] <- prec.y0
  y[1] ~ dt(y.mu[1], y.tau[1], k) 
  y_rep[1] ~ dt(y.mu[1], y.tau[1], k)
  for(i in 2:n) {
    y.mu[i] <- rho*eta[i]*exp(h[i]/2) + beta0 + beta1*y[i-1]
    y.tau[i] <- exp(-h[i])
    y[i] ~ dt(y.mu[i], y.tau[i],k)
    y_rep[i] ~ dt(y.mu[i], y.tau[i],k)
  }
}"

eur2usd.data2 <- list(n=n-3,y=y, mean.y0=y[1], prec.y0=1,
                     beta.mu.0=0,beta.tau.0=0.001,
                     beta.mu.1=0,beta.tau.1=0.001,
                     mu.mu=0,mu.tau=0.001,
                     sigma.a=1,sigma.b=1)


num.chains <- 5
# Compile and run the model
model2 <- jags.model(file=textConnection(model2_string), 
                        data=eur2usd.data2,
                        n.chains=num.chains)
# Burnin for 50000 samples
update(model2,50000)

```

We printed out the posterior summaries for the model parameters beta0, beta1, mu, phi, rho, sigma and nu using the `summary(res.model1)` command. We can see that the standard deviations are relatively smaller than the means in absolute value, indicating that the the amount of data is sufficient to fit the model parameters with some degree of confidence. The time series SE is smaller than the posterior means (in absolute value), showing that our estimates are relatively accurate. From the trace plots, we see that the five chains had overlapped with each other and mixing well, providing no evidence of divergence. 
```{r}
# Running the model, monitoring the variable theta
res.model2=coda.samples(model2,variable.names=c("beta0", "beta1", "mu", "phi", "sigma", "rho", "k"), n.iter=50000,progress.bar="none")

#Setting margins to be small
summary(res.model2); 
par(mar=c(1,1,1,1))
plot(res.model2)
```

We plotted the autocorrelation functions for the seven hyperparameters using the `acf` function. We set the `lag.max` parameter to $1000$ to clearly display the plots. We can see that the samples suffer from more autocorrelation at first. However, the autocorrelations decrease as the lag increases, and they are almost gone after a lag of $500$. 

```{r}
par(mfrow = c(2,2))
par(mar=c(1,1,1,1))
acf(res.model2[[1]][,"beta0"],lag.max=1000,main="ACF for beta0")
acf(res.model2[[1]][,"beta1"],lag.max=1000,main="ACF for beta1")
acf(res.model2[[1]][,"mu"],lag.max=1000,main="ACF for mu")
acf(res.model2[[1]][,"phi"],lag.max=1000,main="ACF for phi")
acf(res.model2[[1]][,"rho"],lag.max=1000,main="ACF for rho")
acf(res.model2[[1]][,"sigma"],lag.max=1000,main="ACF for sigma")
acf(res.model2[[1]][,"k"],lag.max=1000,main="ACF for k")
```

The effective sample sizes are shown below. We see all the parameters have ESS larger than $1000$ with $50000$ burnin and $5000$ samples for $5$ chains. However, since the burnin and sample size are both much larger than the ESS, this again indicates the samples were much correlated at the first few iterations. Nevertheless, there are at least over $1000$ independent samples which is considered enough for posterior inference.

```{r}
effectiveSize(res.model2);
```


**c)[10 marks]**

**Perform posterior predictive checks on both models a) and b). Explain
how did you choose the test functions.**

**Discuss the results.** 

### Posterior predictive checks for (a)

In this part, we use the samples got from (a) and (b) to do posterior predictive checks. Since a vector of NA representing replications `y_rep` has been created in each model strings in previous section, we do not need to write another model string and compile again. Here we sample $50000$ replications for each date between 2000-01-03 to 2000-04-02 by `coda.samples`,  with `y_rep` included in `variable.names`.

```{r}
# Running the model, monitoring the variable theta
res.model1_check=coda.samples(model1,variable.names=c("y_rep"), n.iter=50000)
res.model2_check=coda.samples(model2,variable.names=c("y_rep"), n.iter=50000)
```

The observations with NA values from the replicates have pruned out since they would distort the results. We compare the values of the functions median and mean on the response variable (log(exchange rate)) with the histograms of the replicates. Since the response variable takes very small numbers around zero which are very sensitive, the outliers would strongly affect the minimum and the maximum values, and thus we do not very interested in the max/min plots. As we can see from below, the true true median and true mean all lie inside the area where the median/mean of replications has positive density. In particular, we see the true median and mean are around the peak of the density of replicated medians, which is an indication of good fit.
```{r}
y1rep <- res.model1_check[[1]]
y.not.NA <- which(!is.na(y))
y1rep.not.NA <- as.matrix(y1rep[,y.not.NA])

y2rep <- res.model2_check[[1]]
y2rep.not.NA <- as.matrix(y2rep[,y.not.NA])

par(mar=c(1,1,1,1))
par(mfrow=c(2,2))

y1rep.not.NA.median=apply(y1rep.not.NA,1,median)
hist(y1rep.not.NA.median,col="gray40",xlab="Median of replications (M1)") 
abline(v=median(y,na.rm = TRUE),col="red",lwd=2)

y1rep.not.NA.mean=apply(y1rep.not.NA,1,mean)
hist(y1rep.not.NA.mean,col="gray40",xlab="Mean of replications (M1)") 
abline(v=mean(y,na.rm = TRUE),col="red",lwd=2)

y2rep.not.NA.median=apply(y2rep.not.NA,1,median)
hist(y2rep.not.NA.median,col="gray40",xlab="Median of replications (M2)") 
abline(v=median(y,na.rm = TRUE),col="red",lwd=2)

y2rep.not.NA.mean=apply(y2rep.not.NA,1,mean)
hist(y2rep.not.NA.mean,col="gray40",xlab="Mean of replications (M2)") 
abline(v=mean(y,na.rm = TRUE),col="red",lwd=2)

```

The DIC values have been computed by the `dic.samples` function applied on the JAGS model. The penalized deviance values are `r sum(dic1$deviance)+penalty` for model 1 and `r sum(dic2$deviance)+penalty` for model 2.

```{r}
dic1 <- dic.samples(model1, n.iter=10000)
dic2 <- dic.samples(model2, n.iter=10000)
```

We calculate the posterior mean for the replicated values by averaging the posterior MCMC samples given by the two models. After taking the exponential, we get the replicated values of exchange rate. The following graph show the exchange rates given by the two models as well as the true observations. We can see the two models replicate the true exchange rates reasonably well.

```{r}
y1rep.mu <- c()
y2rep.mu <- c()
for (i in 1:length(y.not.NA)){
  y1rep.mu[i] <- mean(y1rep.not.NA[,i])
  y2rep.mu[i] <- mean(y2rep.not.NA[,i])
}

plot(exp(y[y.not.NA]),ylab="Exchange rate(USD/EUR")
points(exp(y1rep.mu[-1]),col="blue")
points(exp(y2rep.mu[-1]),col="red") 

```

**d)[10 marks]**

**Based on your models a) and b), plot the posterior predictive
densities of the USD/EUR rate on the dates 2000-04-03, 2020-04-04 and
2020-04-05 (the next 3 days after the period considered). Compute the
posterior means and 95% credible intervals. Discuss the results.**

We have included the additional days in the dataset as
NAs (see part(a) where the data was processed). We re-run the model from part (a) and (b)
and obtained the samples, which contain the
posterior samples for the 3 additional days. We have plotted the
evolution of the mean and the 95% credible intervals.

```{r}
eur2usd.data3 <- list(n=n,y=y, mean.y0=y[1], prec.y0=1,
                     beta.mu.0=0,beta.tau.0=0.001,
                     beta.mu.1=0,beta.tau.1=0.001,
                     mu.mu=0,mu.tau=0.001,
                     sigma.a=1,sigma.b=1)

# compiling the model
model3a <- jags.model(textConnection(model1_string),
                     data = eur2usd.data3,n.chains=5)

model3b <- jags.model(textConnection(model2_string),
                     data = eur2usd.data3,n.chains=5)

# burn-in for 50000 samples
update(model3a, 50000)
update(model3b, 50000)

# running the model for 50000 iterations, monitoring y
res.model1_pred=coda.samples(model3a,variable.names=c("y"), n.iter=50000)
res.model2_pred=coda.samples(model3b,variable.names=c("y"), n.iter=50000)

# display summary
#summary(res.model3)
effectiveSize(res.model3a)
effectiveSize(res.model3b)
```

```{r}
y1.predict = as.matrix(res.model1_pred)[,(n-3):(n)]
y2.predict = as.matrix(res.model2_pred)[,(n-3):(n)]

# Combine the results from all chains into a single dataframe
y1.mean=apply(y1.predict, MARGIN=2, FUN=mean)
y1.q025=apply(y1.predict, MARGIN=2, FUN=function(x) quantile(x,prob=0.025))
y1.q975=apply(y1.predict, MARGIN=2, FUN=function(x) quantile(x,prob=0.975))

y1.mean.exp = exp(y1.mean)
y1.q025.exp = exp(y1.q025)
y1.q975.exp = exp(y1.q975)

y2.mean=apply(y2.predict, MARGIN=2, FUN=mean)
y2.q025=apply(y2.predict, MARGIN=2, FUN=function(x) quantile(x,prob=0.025))
y2.q975=apply(y2.predict, MARGIN=2, FUN=function(x) quantile(x,prob=0.975))

y2.mean.exp = exp(y2.mean)
y2.q025.exp = exp(y2.q025)
y2.q975.exp = exp(y2.q975)


par(mfrow=c(1,2))
plot((n-3):(n), y1.mean.exp,type="l",
     main="Posterior mean and 95% credible intervals for log exrates", 
     xlab="day",ylab="Log exchange rates (USD/EUR)",ylim=c(0.9,1.1),col="dark red")
lines((n-3):(n), y1.q025.exp,lty=2,col="dark red")
lines((n-3):(n), y1.q975.exp,lty=3,col="dark red")

plot((n-3):(n), y2.mean.exp,type="l",
     main="Posterior mean and 95% credible intervals for log exchange rates", 
     xlab="day",ylab="Log exchange rates (USD/EUR)",ylim=c(0.9,1.1),col="dark red")
lines((n-3):(n), y2.q025.exp,lty=2,col="dark red")
lines((n-3):(n), y2.q975.exp,lty=3,col="dark red")
```

We also plot the posterior predictive densities as follows. The figures shows the density of the logarithm of exchange rates given by the two models. From the plots we see the two models give similar results.

```{r}
par(mar=c(1,1,1,1))
par(mfrow=c(2,2))
# density plot of predicted response i.e. log(exchange rates)
plot(density(y1.predict[,1]),col="red",main="04-02 log rate")
lines(density(y2.predict[,1]),col="blue")
legend("topright", legend=c("Model 1", "Model 2"),
       col=c("red", "blue"), lty=1, cex=0.5)

plot(density(y1.predict[,2]),col="red",main="04-03")
lines(density(y2.predict[,2]),col="blue")
legend("topright", legend=c("Model 1", "Model 2"),
       col=c("red", "blue"), lty=1, cex=0.5)

plot(density(y1.predict[,3]),col="red",main="04-04")
lines(density(y2.predict[,3]),col="blue")
legend("topright", legend=c("Model 1", "Model 2"),
       col=c("red", "blue"), lty=1, cex=0.5)

plot(density(y1.predict[,4]),col="red",main="04-05")
lines(density(y2.predict[,4]),col="blue",)
legend("topright", legend=c("Model 1", "Model 2"),
       col=c("red", "blue"), lty=1, cex=0.5)
```

**e)[10 marks]**

**In this question, we are going to look use a multivariate stochastic
volatility model with leverage to study the USD/EUR and GBP/EUR exchange
rates jointly. The model is described as follows,**

$\begin{aligned}\boldsymbol{y}_t&=\boldsymbol{\beta}_0+\boldsymbol{\beta}_1 \boldsymbol{y}_{t-1}+\exp(h_t/2)\boldsymbol{\epsilon}_t \quad \text{for}\quad 1\le t\le T,\\ \boldsymbol{h}_{t+1}&=\boldsymbol{\phi}(\boldsymbol{h}_t)+\boldsymbol{\eta}_t\quad \text{for} \quad 0\le t\le T, \quad h_0\sim N(0, I),\\ (\epsilon_t,\eta_t)&\sim N\left(0, \Sigma\right).\end{aligned}$

**Here I denotes the 2 x 2 identity matrix,**
$\boldsymbol{y}_t, \boldsymbol{\beta}_0, \boldsymbol{h}_t, \boldsymbol{\eta}_t, \boldsymbol{\epsilon}_t$
**are 2 dimensional vectors,** $\boldsymbol{\beta}_1$ **and**
$\boldsymbol{\phi}$ **are 2 x 2 matrices,** $\boldsymbol{\Sigma}$ **is a
4 x 4 covariance matrix. At each time step** $t$**, the two components
of** $y_t$ **will be used to model the USD/EUR and GBP/EUR exchange
rates, respectively.**

**Implement this model in JAGS or Stan.**

\*\*Discuss your choices for priors for every parameter [Hint: you can
use Wishart or scaled Wishart priors for\*\*\*\* $\boldsymbol{\Sigma}$,
\*\*see
<https://www.stats.ox.ac.uk/~nicholls/MScMCMC15/jags_user_manual.pdf> ,
<https://mc-stan.org/docs/2_19/functions-reference/wishart-distribution.html>].

**Fit the model, do convergence diagnostics, print out the summary of
the results, and discuss them.**

First, we create a new dataset which includes the exchange rates GBP/EUR. Following the same strategy as in part (a), we fill 
```{r}
usd_gbp <- exrates %>% 
  filter(date <= "2000/04/02") %>%
  mutate(date=as.numeric(date)) %>%
  select(USD,GBP,date) %>%
  mutate(date=date-date[1]+1,USD=log(USD),GBP=log(GBP))
```

```{r}
n <- usd_gbp$date[length(usd_gbp$date)]
y_2d <- data.frame(GBP=rep(NA, n),USD=rep(NA,n))
j <- 1
for(i in usd_gbp$date){
  y_2d[i,1] <- usd_gbp$USD[j]
  y_2d[i,2] <- usd_gbp$GBP[j]
  j <- j+1
}
```

```{r}
model_string <- "model {
  # prior
  Beta0 ~ dmnorm(Beta.mu.0, Beta.Omega.0)
  Beta1 ~ dmnorm(Beta.mu.1, Beta.Omega.1)
  mu ~ dnorm(mu.mu,mu.tau)
  trans_phi ~ dBeta(20,1.5)
  phi <- 2*trans_phi-1
  tau ~ dgamma(sigma.a,sigma.b) 
  sigma <- pow(tau,-1/2)
  trans_rho ~ dBeta(3,5)
  rho <- 2*trans_phi-1
  # Likelihood
  h[1] ~ dnorm(mu, (1-phi^2)*tau)
  #The evolution of the hidden states x according to the model
  for(i in 2:(n+1)) {
    Beta0[1]+Beta1[1,1]*y_h
    y_h[i] ~ dmnorm(mu, Omega)
  }
  
  y[1] ~ dnorm(mean.y0,prec.y0)
  y.var[1] <- prec.y0^(-1)
  for(i in 2:n) {
    y.mu[i] <- rho/sigma*exp(h[i]/2)*(h[i+1]-mu-phi*(h[i]-mu))+Beta0 + Beta1*y[i-1]
    y.var[i] <- exp(h[i])*(1-rho^2) 
    y[i] ~ dnorm(y.mu[i], pow(y.var[i],-1))
  }


}"

```



![](nba.jpg)

**Problem 2 - NBA data**

**In this problem, we are going to construct a predictive model for NBA
games.**

**We start by loading the dataset.**

```{r}
games<-read.csv("games.csv")
teams<-read.csv("teams.csv")
```

**games.csv contains the information about games such as GAME_DATE,
SEASON, HOME_TEAM_ID, VISITOR_TEAM_ID, PTS_home (final score for home
team) and PTS_away (final score for away team).**

**teams.csv contains the names of each team, i.e. the names
corresponding to each team ID.**

**We are going to fit some Bayesian linear regression models on the
scores of each team.**

**You can use either INLA, JAGS or Stan.**

**a)[10 marks]**

**The dataset contains data from 20 seasons, but we are going to focus
on only one, the 2021 season.\
Please only keep games where SEASON is 2021 in the dataset, and remove
all other seasons.\
Please order the games according to the date of occurrence (they are not
ordered like that in the dataset).**

**The scores are going to be assumed to follow a linear Gaussian
model,**

$$S_g^{H}\sim N(\mu_{g}^{H},\sigma^2), \quad S_g^{A}\sim N(\mu_{g}^{A}, \sigma^2).$$

**Here** $S_g^H$ **denotes the final score of the home team in game**
$g$**, and** $S^A_g$ **denotes the final score of the away team in
game** $g$**.**

**Note that the true scores can only take non-negative integer values,
so the Gaussian distribution is not perfect, but it can still be used
nevertheless.**

**The means for the scores are going to be modeled as a combination of
three terms: attacking strength, defending ability, and whether the team
is playing at home, or away. For each team, we denote their attacking
strength parameter by** $a_{team}$**, their defending strength parameter
by** $d_{team}$**, and the effect of playing at home as** $h$**. This
quantifies the effect of playing at home on the expected number of goals
scored. Our model is the following (**$\mu_g^{H}$ **is for the goals
scored by the home team, and is** $\mu_g^{A}$ **is for the away team):**

$\begin{aligned} \mu_{g}^{H}&= \beta_0+a_{home.team}+d_{away.team}+h\\ \mu_{g}^{A}&= \beta_0+a_{away.team}+d_{home.team} \end{aligned}$

**Implement this model. Select your own prior distributions for the
parameters, and discuss the reason for using those priors.**

**Obtain the summary statistics for the posterior distribution of the
model parameters.**

**Evaluate the root mean square error (RMSE) of your posterior means
versus the true scores.**

**Interpret the results.**

First, we select season 2021 data from the game dataset by the R function `filter`, and then arrange the data by the game date. The following figure shows the density of final scores of home team and away team respectively. We can see they are different, and thus infer there may be some "home effects" on the final scores achieved.
```{r}
games2021 <- games %>% 
  filter(SEASON %in% c("2021")) %>%
  arrange(GAME_DATE_EST)
  
plot(density(games2021$PTS_home),type="l", col="red",
     main="Density of final points of home team and away team")
lines(density(games2021$PTS_away),type="l",col="blue")
xlab("score")
legend("topright", legend=c("Home", "Away"),
       col=c("red", "blue"), lty=1, cex=0.8)
```

Now we create the dataset for the model fitting. The dataset is supposed to work for all the models in (a) (b) and (c). The categorical covariates `attack`, `defense`, `h` and `h.team` have been created as follows. `h` and `h.team` are both represente home effects. However, `h.team` is home-specific and it is for model 2 (in (b)). We also create a new variable `win` indicating if the current team won the game or lose. This is done by negating the `HOME_TEAM_WINS` to get the game state (win/lose) of away team and binding them together.

```{r}
# bind the final points of the home team and away team
games.y <- c(games2021$PTS_home, games2021$PTS_away)
# number of games in season 2021
G <- nrow(games2021)

# make home/away team id as chategorical variables
HT_char <- as.character(games2021$HOME_TEAM_ID)
AT_char <- as.character(games2021$VISITOR_TEAM_ID)
# bind the home/away team id as a single vector
attack <- as.factor(c(HT_char,AT_char))
defense <- as.factor(c(AT_char,HT_char))
# create home effect binary variable (also a categorical variate)
# if the team is at home, set home factor to 1 and 0 otherwise
h <- c(rep(1,G),rep(0,G))
h.team <- c(as.character(games2021$HOME_TEAM_ID),rep(0,G))
VISITOR_TEAM_WINS <- as.integer(!as.integer(games2021$HOME_TEAM_WINS))
win <- as.factor(c(games2021$HOME_TEAM_WINS, VISITOR_TEAM_WINS))


games2021 <- games2021 %>% 
  mutate(VISITOR_TEAM_WINS=VISITOR_TEAM_WINS)
```

As in part (c) we are going to use the cumulative average final scores and the result of last game of each team, the statistics is calculated here. For cumulative average final scores, we first arrange `game2021` by game date and then group by the home team ID, so that within each home team the data is in a chronological order. For each group, we calculate the average final scores till the last game (i.e. the current game is not included). Similarly, to determine if a team won the last game or not, we look at the result one game ahead following the game date order. For the first game of each team, we set the averaged scores and last game result to zero, simply because there is no game in this season that can lead potential effects on the team performances, and we believe the results in the last season have no effects on this season or they are negligible. All the data is stored in `model.data2021`.
```{r}
home_avr <- games2021 %>%
  arrange(GAME_DATE_EST) %>%
  group_by(HOME_TEAM_ID) %>%
  mutate(avr=(cumsum(PTS_home)-PTS_home) / (seq_along(PTS_home)-1))
home_avr$avr[is.na(home_avr$avr)] <- 0

away_avr <- games2021 %>%
  arrange(GAME_DATE_EST) %>%
  group_by(VISITOR_TEAM_ID) %>%
  mutate(avr=(cumsum(PTS_away)-PTS_away) / (seq_along(PTS_away)-1))
away_avr$avr[is.na(away_avr$avr)] <- 0

home.last.res <- games2021 %>% 
  arrange(GAME_DATE_EST) %>%
  group_by(HOME_TEAM_ID) %>%
  mutate(last=c(0,HOME_TEAM_WINS[(seq_along(PTS_home)-1)]))


away.last.res <- games2021 %>% 
  group_by(VISITOR_TEAM_ID) %>%
  arrange(GAME_DATE_EST) %>%
  mutate(last=c(0,VISITOR_TEAM_WINS[(seq_along(PTS_away)-1)]))

avr.scores.h <- c(home_avr$avr,away_avr$avr)
avr.scores.a <- c(away_avr$avr,home_avr$avr)
last.res.h <- c(home.last.res$last,away.last.res$last)
last.res.a <- c(away.last.res$last,home.last.res$last)

# model data
model.data2021 <- data.frame(games.y,attack,defense,h.team,h,
                             avr.scores.h, avr.scores.a,
                             last.res.h,last.res.a)
```

After creating the dataset, we fit the model as required in question (a). Since the likelihood is Gaussian, we use the conjugate prior for precision. It is expected that the precision has a mean 1 and variance 10, therefore by moment matching we use $1/\sigma^2\sim \text{Gamma}(0.1,0.1)$. For all the covariates, we put non-informative normal priors $\mathcal{N}(0,100)$. We set the prior mean at 0, and the precision of as 10 (i.e. our expectation is that the regression coefficients are not more than 1 in absolute value, since we are working with categorical covariates). The model has been implemented using `INLA` as below. By using `control.compute` option, it is ensured that CPO and DIC are computed. We printed out he summary of the model below. 
```{r}
# prior for model 1
prior.prec <- list(prec=list(prior = "loggamma", param = c(0.1, 0.1)))
prior.fixed <- list(mean.intercept = mean(games.y), prec.intercept = 0.01,
                    mean = 0, prec = 0.01)
# fit model 1
m1.gaussian=inla(formula=games.y~1+attack+defense+h,
                data=model.data2021,family="gaussian",
                control.family=list(hyper=prior.prec),
                control.fixed=prior.fixed,
                control.compute = list(cpo=TRUE,dic=TRUE,config = TRUE,
                                       return.marginals.predictor=TRUE))
```

The summary of model 1 results is shown below.

```{r}
# print out the summary for model 1
summary(m1.gaussian)
```
We have evaluated the DIC, NLSCPO and the standard deviation of the root mean square errors. The root mean square error of the posterior means versus the true scores can be calculated as $RMSE = \sqrt{\frac {\sum(\text{fitted}-\text{true})^2}{n}}$. The results below show a reasonable the root mean square error. The DIC and CPO scores seem to be large, and we are going to improve the model in the following work. 
```{r}
rmse1 <- sqrt(mean((m1.gaussian$summary.fitted.values$mean-games.y)^2))
cat("DIC of model 1:",m1.gaussian$dic$dic,"\n")
cat("NSLCPO of model 1:",-sum(log(m1.gaussian$cpo$cpo)),"\n")
cat("Root mean square error for model 1 1:",rmse1,"\n")
```


**b)[10 marks] In part a), the model assumed that the home effect is the
same for each team. In this part, we consider a team-specific home
effect** $h_{home.team}$,

$\begin{aligned} \mu_{g}^{H}&= \beta_0+a_{home.team}+d_{away.team}+h_{home.team}\\ \mu_{g}^{A}&= \beta_0+a_{away.team}+d_{home.team} \end{aligned}$

**Implement this model. Select your own prior distributions for the
parameters, and discuss the reason for using those priors.**

**Obtain the summary statistics for the posterior distribution of the
model parameters.**

**Evaluate the root mean square error (RMSE) of your posterior means
versus the true scores.**

**Interpret the results.**

In this part, we take the home effect as team-specific, meaning that each team would have different home effect. This is more reasonable than that we assign the same home effect to all the team. By replacing `h` by `h.team` in the regression formula, the model 2 has been implemented. The prior choice is the same as that in (a).
```{r}
m2.data2021=data.frame(games.y,attack,defense,h.team,win)
m2.gaussian=inla(formula=games.y~1+attack+defense+h.team,
                data=model.data2021,family="gaussian",
                control.family=list(hyper=prior.prec),
                control.fixed=prior.fixed,
                control.compute = list(dic = T,config = TRUE,
                                       return.marginals.predictor=TRUE))
summary(m2.gaussian)

```

We have evaluated the DIC, NLSCPO and the standard deviation of the root mean square errors. The root mean square error of the posterior means versus the true scores can be calculated as $RMSE = \sqrt{\frac {\sum(\text{fitted}-\text{true})^2}{n}}$. Looking at the root mean square error (11.48), it is smaller than that of model (b) (11.59), which may indicate that the model with home-specific effects performs better.
```{r}
rmse2 <- sqrt(mean((m2.gaussian$summary.fitted.values$mean-games.y)^2))
cat("DIC of model 2:",m2.gaussian$dic$dic,"\n")
cat("NSLCPO of model 2:",-sum(log(m2.gaussian$cpo$cpo)),"\n")
cat("Root mean square error for model 2 :",rmse2,"\n")
```
**c)[10 marks] Propose an improved linear model using the information in
the dataset before the game (you cannot use any information in the same
row as the game, as this is only available after the game). Hint: you
can try incorporating running averages of some covariates specific to
each team, by doing some pre-processing.**

**Implement your model. Select your own prior distributions for the
parameters, and discuss the reason for using those priors.**

**Obtain the summary statistics for the posterior distribution of the
model parameters.**

**Evaluate the root mean square error (RMSE) of your posterior means
versus the true scores.**

**Interpret the results.**
After looking at the games dataset, we think the historical game final results and final scores might have some influence on the team performances and thus influence the result of the current game. Therefore, we would like to add two more features `last.res` and `avr.scores`. `last.res` takes binary values, 0 indicating the team lost its last game and 1 indicating the team won its last team. `avr.scores` summarises the average final scores of each team till its latest game (and the current game is not included). The detail of the preprosessing can be found in part (a) where the model data was created. Based on that, the following models are to be tested.

Model 3a:
$$
\begin{aligned} \mu_{g}^{H}&= \beta_0+a_{home.team}+d_{away.team}+h_{home.team}\\ &+\text{avr.scores}_{home.team}+\text{avr.scores}_{away.team}+\text{last.res}_{home.team}+\text{last.res}_{away.team}\\ 
\mu_{g}^{A}&= \beta_0+a_{away.team}+d_{home.team} \\
&+\text{avr.scores}_{home.team}+\text{avr.scores}_{away.team}+\text{last.res}_{home.team}+\text{last.res}_{away.team}
\end{aligned}
$$

Model 3b: (Compared with 3a, we include the interaction effect of last game result and average scores of home team for home teams as well as the interaction effect of last game result and average scores of away team for away teams)
$$
\begin{aligned} \mu_{g}^{H}&= \beta_0+a_{home.team}+d_{away.team}+h_{home.team}\\ &+\text{avr.scores}_{home.team}+\text{avr.scores}_{away.team}+\text{last.res}_{home.team}+\text{last.res}_{away.team}\\
& + \text{avr.scores}_{home.team}*\text{last.res}_{home.team}\\
\mu_{g}^{A}&= \beta_0+a_{away.team}+d_{home.team} \\
&+\text{avr.scores}_{home.team}+\text{avr.scores}_{away.team}+\text{last.res}_{home.team}+\text{last.res}_{away.team}\\
& + \text{avr.scores}_{away.team}*\text{last.res}_{away.team}\\
\end{aligned}
$$
Model 3c: (Compared with 3a, we include the interaction effect of last game result and average scores of both home and away team.)
$$
\begin{aligned} \mu_{g}^{H}&= \beta_0+a_{home.team}+d_{away.team}+h_{home.team}\\ &+\text{avr.scores}_{home.team}+\text{avr.scores}_{away.team}+\text{last.res}_{home.team}+\text{last.res}_{away.team}\\
& + \text{avr.scores}_{home.team}*\text{last.res}_{home.team}+\text{avr.scores}_{away.team}*\text{last.res}_{away.team}\\
\mu_{g}^{A}&= \beta_0+a_{away.team}+d_{home.team} \\
&+\text{avr.scores}_{home.team}+\text{avr.scores}_{away.team}+\text{last.res}_{home.team}+\text{last.res}_{away.team}\\
& + \text{avr.scores}_{home.team}*\text{last.res}_{home.team}+\text{avr.scores}_{away.team}*\text{last.res}_{away.team}\\
\end{aligned}
$$
Using the same priors as before, we implemented the above three models in inla.
```{r}
m3a.gaussian<-inla(formula=games.y~1+attack+defense+h.team+
                    avr.scores.h+avr.scores.a+
                    last.res.h+last.res.a,
           data=model.data2021,
           family = "gaussian", 
           control.fixed=prior.fixed,
           control.family=list(hyper=prior.prec),
           control.compute = list(dic = T,config = TRUE,
                                  return.marginals.predictor=TRUE))

```
```{r}
m3b.gaussian<-inla(formula=games.y~1+attack+defense+h.team+avr.scores.h+avr.scores.a+
                    last.res.h+last.res.a+
                    I(avr.scores.h*last.res.h)+I(avr.scores.h*last.res.h),
           data=model.data2021,
           family = "gaussian", 
           control.fixed=prior.fixed,
           control.family=list(hyper=prior.prec),
           control.compute = list(dic = T,config = TRUE,
                                       return.marginals.predictor=TRUE))
```
```{r}
m3c.gaussian<-inla(formula=games.y~1+attack+defense+h.team+avr.scores.h+avr.scores.a+
                    last.res.h+last.res.a+
                    I(avr.scores.h*last.res.h)+I(avr.scores.h*last.res.h)+
                     I(avr.scores.a*last.res.a)+I(avr.scores.a*last.res.a),
           data=m2.data2021,
           family = "gaussian",
           control.fixed=prior.fixed,
           control.family=list(hyper=prior.prec),
           control.compute = list(dic = T,config = TRUE,
                                       return.marginals.predictor=TRUE))
```

We computed the root mean square errors for the three models. As we can see, model 3c gives the least value. Therefore, we decided to use model3c to do analysis hereafter and we would call model 3c as model 3 for brevity.
```{r}
rmse3 <- sqrt(mean((m3a.gaussian$summary.fitted.values$mean-games.y)^2))
rmse3
rmse4 <- sqrt(mean((m3b.gaussian$summary.fitted.values$mean-games.y)^2))
rmse4
rmse5 <- sqrt(mean((m3c.gaussian$summary.fitted.values$mean-games.y)^2))
rmse5
```

Below is the summary of results by model3. 
```{r}
summary(m3c.gaussian)
```


**d)[10 marks] Perform posterior predictive checks on all 3 models a),
b), and c). Explain how did you choose the test functions.**

**Discuss the results.**

In this part, we would compute the studentized residuals for the Bayesian regression model
from part (a) (b) and (c). 
We have implemented the studentization using dummy variables to encode categorical covariates. This is possible to implement using the `dummies` library in R.
We only computed the diagonal elements for the H matrix as these are the only ones required for this problem.
We do have some elements in the diagonal of H that are 1, due to those categorical variables (attack, defense,h.team) only appearing once in the dataset.
Studentization is not appropriate in such cases (as it would mean division by 0), so we change H[i,i] from 1 to 0 for these positions. 
```{r}
attack_id_dummies=dummy(model.data2021$attack)
attack_id_dummies_except_first=attack_id_dummies[,2:ncol(attack_id_dummies)]

defense_id_dummies=dummy(model.data2021$defense)
defense_id_dummies_except_first=defense_id_dummies[,2:ncol(defense_id_dummies)]

h.team_id_dummies <- dummy(model.data2021$h.team)
h.team_id_dummies_except_first=h.team_id_dummies[,2:ncol(h.team_id_dummies)]

nsamp <- 1000
samp1 <- inla.posterior.sample(nsamp, m1.gaussian)
samp2 <- inla.posterior.sample(nsamp, m2.gaussian)
samp3 <- inla.posterior.sample(nsamp, m3.gaussian)

sigma1=1/sqrt(inla.posterior.sample.eval(function(...) {theta},
  samp1))
sigma2=1/sqrt(inla.posterior.sample.eval(function(...) {theta},
  samp2))
sigma3=1/sqrt(inla.posterior.sample.eval(function(...) {theta},
  samp3))

#In this model the link function is the identity, so fitted values are the same as the linear predictors 
#(E(y_i|x,theta)=mu_i=eta_i)
fittedvalues1=inla.posterior.sample.eval(function(...) {Predictor},
samp1)
fittedvalues2=inla.posterior.sample.eval(function(...) {Predictor},
samp2)
fittedvalues3=inla.posterior.sample.eval(function(...) {Predictor},
samp3)

n=nrow(model.data2021)

#Storing x as a sparse matrix, with categorical variables encoded as dummies
#Using sparse matrices can speed up calculations in this example
x1 <- Matrix(cbind(rep(1,n), attack_id_dummies_except_first, 
               defense_id_dummies_except_first,
               model.data2021$h),sparse=TRUE)
x2 <- Matrix(cbind(rep(1,n), attack_id_dummies_except_first, 
               defense_id_dummies_except_first,
               h.team_id_dummies_except_first),sparse=TRUE)
x3 <- Matrix(cbind(rep(1,n), attack_id_dummies_except_first, 
               defense_id_dummies_except_first,
               h.team_id_dummies_except_first,
               model.data2021$avr.scores,
               model.data2021$last.res),sparse=TRUE)

A1=solve(t(x1)%*%x1,t(x1))
A2=solve(t(x2)%*%x2,t(x2))
A3=solve(t(x3)%*%x3,t(x3))
Hdiag1=apply(x1*t(A1),MARGIN=1,sum)
Hdiag2=apply(x2*t(A2),MARGIN=1,sum)
Hdiag3=apply(x3*t(A3),MARGIN=1,sum)

#We do have some elements in H[i,i] that are 1, due to those categorical variables (horses) only appearing once in the dataset.
#Studentization is not appropriate in such cases (as it would mean division by 0), so we change H[i,i] from 1 to 0 for these positions
Hdiag1[Hdiag1==1]=0
Hdiag2[Hdiag2==1]=0
Hdiag3[Hdiag3==1]=0
#Previously, we have computed the whole H matrix using the formula
#H=x%*%solve(t(x)%*%x,t(x))
#This can be quite slow in this example, and also use a lot of memory when the number of data points is large. 
#Since we only use the diagonal terms, it suffices to only compute those,
#meaning that the memory usage and computational time can be significantly improved.
#The diagonal terms H[i,i] can be computed by the scalar product of the ith row of x and the ith column of A=(t(x)*x)^{-1} * t(x)
#This is computed for each i and the results are stored in a vector using the apply(x*t(A),MARGIN=1,sum) command.
#Here MARGIN=1 tells the apply function to evalue the sum function along the rows (MARGIN=2 would correspond to columns).

#studentised residuals
#n is the number of rows in the dataset, i.e. the number of observations
#studentised residuals
studentisedred1=matrix(0,nrow=n,ncol=nsamp)
studentisedred2=matrix(0,nrow=n,ncol=nsamp)
studentisedred3=matrix(0,nrow=n,ncol=nsamp)
#create a matrix of size n * nsamp, repeating y in each column

ymx=as.matrix(games.y)%*%matrix(1,nrow=1,ncol=nsamp);

studentisedred1=ymx-fittedvalues1;
studentisedred2=ymx-fittedvalues2;
studentisedred3=ymx-fittedvalues3;

for(l in 1:nsamp){
  studentisedred1[,l]=studentisedred1[,l]/sigma1[l];
  studentisedred2[,l]=studentisedred2[,l]/sigma2[l];
  studentisedred3[,l]=studentisedred3[,l]/sigma3[l];
}

for(i in 1:n){
  studentisedred1[i,]=studentisedred1[i,]/sqrt(1-Hdiag1[i]);
  studentisedred2[i,]=studentisedred2[i,]/sqrt(1-Hdiag2[i]);
  studentisedred3[i,]=studentisedred3[i,]/sqrt(1-Hdiag3[i]);
}


#posterior mean of studentised residuals
studentisedredm1=numeric(n)
studentisedredm2=numeric(n)
studentisedredm3=numeric(n)
for(i in 1:n){
  studentisedredm1[i]=mean(studentisedred1[i,])  
  studentisedredm2[i]=mean(studentisedred2[i,])  
  studentisedredm3[i]=mean(studentisedred3[i,])  
}

```

We performed a simple Q-Q plot on the studentized
residuals, the studentized residuals versus their index, and also
plot the studentized residuals against the posterior mean of the fitted
value for each of the three models in (a), (b) and (c). From the studentized residual plots, we see no significant structure here, i.e. the posterior means of
the residuals does not have a clear dependence on the index or the fitted value. 
```{r}
#Plot of posterior mean studentised residual versus observation number.
par(mfrow=c(1,3))
plot(seq_along(studentisedredm1),studentisedredm1,xlab="Index",
     ylab="Bayesian studentised residual")
plot(seq_along(studentisedredm2),studentisedredm2,xlab="Index",
     ylab="Bayesian studentised residual")
plot(seq_along(studentisedredm3),studentisedredm3,xlab="Index",
     ylab="Bayesian studentised residual")


#Compute posterior mean fitted values
fittedvaluesm1=numeric(n)
fittedvaluesm2=numeric(n)
fittedvaluesm3=numeric(n)
for(i in 1:n){
fittedvaluesm1[i]=mean(fittedvalues1[i,])
fittedvaluesm2[i]=mean(fittedvalues2[i,])
fittedvaluesm3[i]=mean(fittedvalues3[i,])
}

par(mfrow=c(1,3))
plot(fittedvaluesm1,studentisedredm1,xlab="Fitted value (posterior mean)",
     ylab="Bayesian Studentised residual (posterior mean)")
plot(fittedvaluesm2,studentisedredm2,xlab="Fitted value (posterior mean)",
     ylab="Bayesian Studentised residual (posterior mean)")
plot(fittedvaluesm3,studentisedredm3,xlab="Fitted value (posterior mean)",
     ylab="Bayesian Studentised residual (posterior mean)")

```

On the QQ-plots, the fits are reasonably good for small deviations. We see that the Model 1 fit
is relatively poor in the tails compared with other two models. This again indicates that the model 1 would be less favoured here.

```{r}
#QQ-plot
par(mfrow=c(1,3))
qqnorm(studentisedredm1,xlim=c(-3.5,3.5),ylim=c(-3.5,3.5),lwd=2)
qqline(studentisedredm1,col=2,lwd=2)
qqnorm(studentisedredm2,xlim=c(-3.5,3.5),ylim=c(-3.5,3.5),lwd=2)
qqline(studentisedredm2,col=2,lwd=2)
qqnorm(studentisedredm3,xlim=c(-3.5,3.5),ylim=c(-3.5,3.5),lwd=2)
qqline(studentisedredm3,col=2,lwd=2)
```
**e)[10 marks] In the previous questions, we were assuming a model of
the
form.**$$S_g^{H}\sim N(\mu_{g}^{H},\sigma^2), \quad S_g^{A}\sim N(\mu_{g}^{A}, \sigma^2).$$**It
is natural to model these two results jointly with a multivariate
normal,**

$$(S_g^{H}, S_g^{A})\sim N\left(\left(\begin{matrix}\mu_{g}^{H}\\\mu_{g}^{A}\end{matrix}\right),\Sigma\right),$$

**where** $\Sigma$ **is a 2 times 2 covariance matrix.**

**Implement such a model. The definition of** $\mu_g^{H}$ **and**
$\mu_g^{A}$ **can be either one of a), b), or c), you just need to
implement one of them.**

**Explain how did you choose the prior on** $\Sigma$ **[Hint: you can
use a Wishart prior, or express this a product of diagonal and
correlation matrices and put priors on those terms].**

**Obtain the summary statistics for the posterior distribution of the
model parameters.**

**Evaluate the root mean square error (RMSE) of your posterior means
versus the true scores.**

**Interpret the results.**

We implement the model using definition of $\mu_g^H$ and $\mu_g^A$ as in part (c). First we create the joint fixed effects `covariate.joint` by padding the covariates with NAs/0, for factors/numeric covariates respectively. 
We construct a list of the responses home team scores and away team scores
Then, the new dataset `joint.data2021` is constructed by column binding fixed.covariate and random.covariate.
For the covariance matrix, we choose a Wishart prior, while for all the other covariates we follow the default choice of priors in inla. 
```{r}
covariate.joint <- data.frame(
    beta0 = as.factor(c(rep(1, G), rep(2, G))),
    h.attack = as.factor(c(HT_char, rep(NA, G))),
    a.attack = as.factor(c(rep(NA, G), AT_char)),
    h.defense = as.factor(c(AT_char, rep(NA, G))),
    a.defense = as.factor(c(rep(NA, G),HT_char)),
    h.last.res = as.factor(c(home.last.res$last,rep(0,G))),
    a.last.res = as.factor(c(rep(0,G),home.last.res$last)),
    h.avr.scores = as.factor(c(home.last.res$last,rep(0,G))),
    a.avr.scores = as.factor(c(rep(0,G),home.last.res$last)),
    h.team = as.factor(c(as.character(games2021$HOME_TEAM_ID),rep(NA, G))))

PTS <- list(h=c(games2021$PTS_home, rep(NA,G)),
            a=c(rep(NA,G),games2021$PTS_away))

joint.data2021 <- data.frame(PTS=PTS,covariate.joint)

```
```{r}
m.joint <- inla(PTS ~ 1 + beta0 + h.team + h.attack + a.attack + 
                  h.defense + a.defense + 
                  h.last.res + a.last.res + 
                  h.avr.scores + a.avr.scores,
    family = c("gaussian", "gaussian"), data = joint.data2021,
    verbose = FALSE, control.compute = list(dic = TRUE),
    control.family = list(list(), list(hyper = list(theta =
      list(prior = "wishart2d", param = c(4,1,1,2))))))

summary(m.joint)
```

```{r}
cat("Root mean square error for the model is :",
    sqrt(mean((m.joint$summary.fitted.values$mean-games.y)^2)),"\n")

```




