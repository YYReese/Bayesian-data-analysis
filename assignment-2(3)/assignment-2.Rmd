---
editor_options:
  markdown:
    wrap: 72
output: pdf_document
---

**University of Edinburgh**

**School of Mathematics**

**Bayesian Data Analysis, 2022/2023, Semester 2**

**Assignment 2**

**IMPORTANT INFORMATION ABOUT THE ASSIGNMENT**



```{r}
rm(list = ls(all = TRUE))
#Do not delete this!
#It clears all variables to ensure reproducibility
```

![](car_insurance.jpg)

**Problem 1**

**In this problem, we study a dataset about car insurance.** **This data
set is based on one-year vehicle insurance policies taken out in 2004 or
2005. In total, there are 67856 policies, of which 4624 have claims.**

```{r}
require(insuranceData)
require(dplyr)
require(knitr)
require(dummies)
require(rjags)
require(INLA)
data(dataCar)

#You may need to set the working directory first before loading the dataset
#setwd("location of Assignment 1")
#The first 6 rows of the dataframe
print.data.frame(dataCar[1:6,])

```

**Description of the columns.**

**veh_value: vehicle value in \$10000s**

**exposure: maximum portion of the vehicle value the insurer may need to
pay out in case of an incident**

**claimcst0: claim amount (0 if no claim)**

**clm: whether there was a claim during the 1 year duration**

**numclaims: number of claims during the 1 year duration**

**veh_body types: BUS = bus CONVT = convertible COUPE = coupe HBACK =
hatchback HDTOP = hardtop MCARA = motorized caravan MIBUS = minibus
PANVN = panel van RDSTR = roadster SEDAN = sedan STNWG = station wagon
TRUCK = truck UTE = utility**

**gender: F- female, M - male\
\
area: a factor with levels A,B,C,D,E, F**

**agecat: age category, 1 (youngest), 2, 3, 4, 5, 6**

**You can use either JAGS, Stan, or INLA for this question.**

**a)[10 marks] Fit a Bayesian logistic regression model on the dataset
dataCar with**

-   **clm as response,**

-   **a link function of your choice,**

-   **using veh_value, exposure, veh_body, veh_age, gender, area, and
    agecat as covariates (you can use categorical covariates by
    converting integers to factors if appropriate).**

**Center and scale the non-categorical covariates.**

**Choose your own prior distributions (do not use default priors), and
explain the rationale your prior choices, and ensure that the posterior
is not too sensitive to your prior choice [Hint: look at the induced
prior on the linear predictor and on the response.]**

**Compute the posterior means of the model parameters, and discuss the
results.**

```{r}
# Define the functions 
odds <- function(x) x/(1-x) # odds ratio function
logit <- function(x) log(x/(1-x))
ilogit <- function(x){ 1/(1+exp(-x))} #Inverse logistic function
```

In this part, we standardise two non-categorical covariates, veh_value and exposure, and convert veh_age to categorical variable.
```{r}
# Data preprocessing 
car.data.scl <- dataCar %>% 
  select(veh_value, exposure,veh_body, 
         veh_age, gender, area, agecat, clm,numclaims) %>% 
  mutate(veh_value=scale(veh_value), 
         exposure=scale(exposure))

####Car data with categorical covariates - INLA ####
car.inla.data <- car.data.scl %>% 
  select(veh_value, exposure,veh_body, 
         veh_age, gender, area, agecat, clm) %>%
  mutate(veh_body=as.factor(veh_body),area=as.factor(area),
         agecat=as.factor(agecat),veh_age=as.factor(veh_age))
```

### Data exploration
In the following, we compute the odds ratio of different groups of the data which might be useful for prior choices. 
```{r}
odds.body <- c()
for (i in 1:13){
  body <- unique(car.inla.data$veh_body)[i]
  df.body <- car.inla.data %>% filter(veh_body %in% c(body)) 
  odds.body[i] <- odds(sum(df.body$clm == 1)/nrow(df.body))
}
body.ratio <- max(odds.body)/min(odds.body)
body.ratio 

odds.gender <- c()
df.m <- car.inla.data %>% filter(gender %in% c("M"))
df.f <- car.inla.data %>% filter(gender %in% c("F"))
odds.gender[1] <- odds(sum(df.m$clm == 1)/nrow(df.m))
odds.gender[2] <- odds(sum(df.f$clm == 1)/nrow(df.f))
gender.ratio <- max(odds.gender)/min(odds.gender)
gender.ratio

odds.area <- c()
for (i in 1:6){
  a <- unique(car.inla.data$area)[i]
  df.area <- car.inla.data %>% filter(area %in% c(a)) 
  odds.area[i] <- odds(sum(df.area$clm == 1)/nrow(df.area))
}
area.ratio <- max(odds.area)/min(odds.area)
area.ratio

odds.agecat <- c()
for (i in 1:6){
  age <- unique(car.inla.data$agecat)[i]
  df.agecat <- car.inla.data %>% filter(agecat %in% c(age)) 
  odds.agecat[i] <- odds(sum(df.agecat$clm == 1)/nrow(df.agecat))
}
agecat.ratio <- max(odds.agecat)/min(odds.agecat)
agecat.ratio


odds.v_age <- c()
for (i in 1:4){
  v_age <- unique(car.inla.data$veh_age)[i]
  df.v_age <- car.inla.data %>% filter(veh_age %in% c(v_age)) 
  odds.v_age[i] <- odds(sum(df.v_age$clm == 1)/nrow(df.v_age))
}
v_age.ratio <- max(odds.v_age)/min(odds.v_age)
v_age.ratio

```
From the results, we can see that for veh_body, the odds ratio of one group can be at most $6$ times lager than that of another group. For gender, the odds ratio of female is $0.017$ times lager than that of male. For area, the odds ratio of one group is at most $1.314$ times larger than that of another group. For agecat, the odds ratio of one group is at most $1.601$ times larger than that of another group. For veh_age, the odds ratio of one group is at most $1.239$ times larger than that of another group. Using the information, we set the priors for the regression coefficients of linear predictors as follows.
\begin{itemize}
  \item For veh_body: we want $e^{\beta_3}$ to have large mass at around $6$, so it is reasonable to set prior $\mathcal{N}(0,\sigma_3^2)$ where $\sigma_3=\ln 6$. 
  \item For gender: we want $e^{\beta_5}$ to have large mass at around $1.02$, so we may like to put prior $\mathcal{N}(0,\sigma_5^2)$ where $\sigma_5=\ln 1.02$. However, this looks a bit informative, so we let $\sigma_5=1$ instead. It cause no problem to change the prior to make it vaguer. 
  \item For area: we want $e^{\beta_6}$ to have large mass at around $1.31$, so it is reasonable to set prior $\mathcal{N}(0,\sigma_6^2)$ where $\sigma_6=\ln 1.31$. 
  \item For agecat: we want $e^{\beta_7}$ to have large mass at around $1.6$, so it is reasonable to set prior $\mathcal{N}(0,\sigma_7^2)$ where $\sigma_7=\ln 1.6$. 
  \item For veh_age: we want $e^{\beta_4}$ to have large mass at around $1.24$, so it is reasonable to set prior $\mathcal{N}(0,\sigma_6^2)$ where $\sigma_6=\ln 1.24$. 
  \item For veh_value: we want $e^{\beta_1 x_1}$ to have large mass at around $5$. Having checked the density of scaled value of veh_value variable, we think it takes values mostly between $0$ to $5$. Therefore, it is sensible to set prior $\mathcal{N}(0,\sigma_1^2)$ where $\sigma_1=\ln 5/5$. 
  \item For exposure: we want $e^{\beta_2 x_2}$ to have large mass at around $1.5$. Having check the density of scaled value of exposure, we found it takes values mostly within $-1$ to $1$. Therefore, it is sensible to set prior $\mathcal{N}(0,\sigma_2^2)$ where $\sigma_2=\ln 1.5/1=\ln 1.5$. 
  For the intercept $beta_0$: we want to ensure that the inverse logit of $30$ times $|\beta_0|$ can be in the interval $(-0.05,0.95)$. (Here $30$ is roughly the exponential of all the covariates' effects, i.e. $50\approx e^{\beta_1 x_1 \beta_2 x_2 ...\beta_7}$.) Hence, we come up with the prior $\mathcal{N}(0, \sigma_0)$ for $\beta_0$ where $\sigma_0=log(6)$.
\end{itemize}

Now let us see the induced prior on the probability parameter in Bernoulli distribution $p_i$. We simulate $1000$ points for each beta. Assume we have each all non-categorical covariates equal to 1 (after scaling) and randomly choose a group for all the categorical variables. Then we can compute the responses. After that, the inverse logit of the responses can be computed so that we can plot the density of the probability parameter in Bernoulli distribution, $p_i$. From the following plot, we can see the induced prior on $\mu$ looks okay. We have also tried different values of $x_1,x_2,...$ and the results showed no problem, so we continue with our choices of priors.
```{r}
beta0 <- rnorm(1000,sd=1.79)
beta1 <- rnorm(1000,sd=log(5)/5)
beta2 <- rnorm(1000,sd=log(1.5))
beta3 <- rnorm(1000,sd=log(6))
beta4 <- rnorm(1000,sd=log(1.24))
beta5 <- rnorm(1000,sd=log(1.02))
beta6 <- rnorm(1000,sd=log(1.31))
beta7 <- rnorm(1000,sd=log(1.6))
x <- ilogit( beta0+beta1+beta2+beta3+beta4+beta5+beta6+beta7)
plot(density(x),main="density of the induced prior on the parameter p in Bernoulli")
```



Data block
```{r}
n <- nrow(car.data)
body.dum <- dummy(car.data.ctr$veh_body)
agecat.dum <- dummy(car.data.ctr$agecat)
gen.dum <- dummy(car.data.ctr$gender)
area.dum <- dummy(car.data.ctr$area)
car.logit.data <- list(n=n, body=body.dum[,-1],
                     agecat=agecat.dum[,-1],
                     gender=gen.dum[,-1],
                     area=area.dum[,-1],
                     veh_value=car.data.ctr$veh_value,
                     exposure=car.data.ctr$exposure,
                     veh_age=car.data.ctr$veh_age)

car.logit.data2 <- list(n=n, body.convt=body.dum[,2],
                        body.coupe=body.dum[,3],
                        body.hback=body.dum[,4],
                        body.hdtop=body.dum[,5],
                        body.mcara=body.dum[,6],
                        body.mibus=body.dum[,7],
                        body.panvn=body.dum[,8],
                        body.rdstr=body.dum[,9],
                        body.sedan=body.dum[,10],
                        body.stnwg=body.dum[,11],
                        body.truck=body.dum[,12],
                        body.ute=body.dum[,13],
                        agecat2=agecat.dum[,2],
                        agecat3=agecat.dum[,3],
                        agecat4=agecat.dum[,4],
                        agecat5=agecat.dum[,5],
                        agecat6=agecat.dum[,6],
                        gender=gen.dum[,1],
                        area.B=area.dum[,2],
                        area.C=area.dum[,3],
                        area.D=area.dum[,4],
                        area.E=area.dum[,5],
                        area.F=area.dum[,6],
                        veh_value=car.data.ctr$veh_value,
                        exposure=car.data.ctr$exposure,
                        veh_age=car.data.ctr$veh_age)
```

```{r}
car.logit.model2 <- "model {
 beta.mu.0   <- 0
 beta.tau.0  <- 1/(log(15)^2)
 beta.mu <- 0
 beta.tau <- 1/(log(10)/2)^2
 # prior
 beta0   ~ dnorm(beta.mu.0,beta.tau.0)
 beta.veh_value  ~ dnorm(beta.mu,beta.tau)
 beta.exposure ~ dnorm(beta.mu,beta.tau)
 beta.veh_age    ~ dnorm(beta.mu,beta.tau)
 
 beta.gender.m ~ dnorm(beta.mu,beta.tau)
 
 beta.body.convt ~ dnorm(beta.mu,beta.tau)
 beta.body.coupe ~ dnorm(beta.mu,beta.tau)
 beta.body.hback ~ dnorm(beta.mu,beta.tau)
 beta.body.hdtop ~ dnorm(beta.mu,beta.tau)
 beta.body.mcara ~ dnorm(beta.mu,beta.tau)
 beta.body.mibus ~ dnorm(beta.mu,beta.tau)
 beta.body.panvn ~ dnorm(beta.mu,beta.tau)
 beta.body.rdstr ~ dnorm(beta.mu,beta.tau)
 beta.body.sedan ~ dnorm(beta.mu,beta.tau)
 beta.body.stnwg ~ dnorm(beta.mu,beta.tau)
 beta.body.truck ~ dnorm(beta.mu,beta.tau)
 beta.body.ute ~ dnorm(beta.mu,beta.tau)
 
 beta.area.B ~ dnorm(beta.mu,beta.tau)
 beta.area.C ~ dnorm(beta.mu,beta.tau)
 beta.area.D ~ dnorm(beta.mu,beta.tau)
 beta.area.E ~ dnorm(beta.mu,beta.tau)
 beta.area.F ~ dnorm(beta.mu,beta.tau)
 
 beta.agecat.2 ~ dnorm(beta.mu,beta.tau)
 beta.agecat.3 ~ dnorm(beta.mu,beta.tau)
 beta.agecat.4 ~ dnorm(beta.mu,beta.tau)
 beta.agecat.5 ~ dnorm(beta.mu,beta.tau)
 beta.agecat.6 ~ dnorm(beta.mu,beta.tau)
 
 #Likelihood
 for(i in 1:n) {
   logit(mu[i])  <- beta0+beta.veh_value*veh_value[i] +
               beta.exposure*exposure[i] +beta.veh_age*veh_age[i]
               +beta.gender.m*gender[i]
               +beta.body.convt*body.convt[i]
               +beta.body.coupe *body.coupe[i]
               +beta.body.hback *body.hback[i]
               +beta.body.hdtop *body.hdtop[i]
               +beta.body.mcara *body.mcara[i]
               +beta.body.mibus *body.mibus[i]
               +beta.body.panvn *body.panvn[i]
               +beta.body.rdstr *body.rdstr[i]
               +beta.body.sedan *body.sedan[i]
               +beta.body.stnwg *body.stnwg[i]
               +beta.body.truck *body.truck[i]
               +beta.body.ute *body.ute[i]
               +beta.area.B *area.B[i]
               +beta.area.C *area.C[i]
               +beta.area.D *area.D[i]
               +beta.area.E *area.E[i]
               +beta.area.F *area.F[i]
               +beta.agecat.2 *agecat2[i]
               +beta.agecat.3 *agecat3[i]
               +beta.agecat.4 *agecat4[i]
               +beta.agecat.5 *agecat5[i]
               +beta.agecat.6 *agecat6[i]

   clm[i] ~ dbern(mu[i])
   clm.rep[i] ~ dbern(mu[i])
 } 
}"
```
```{r}
# Run JAGS to the completion of the "adaption" stage 
results.car.logit2 <- jags.model(file=textConnection(car.logit.model2), 
                                   data=car.logit.data2,
                                   n.chains=3)

# Burn-in of 10000 iterations
update(results.car.logit2, n.iter=10000)

# Longer run for making inferences, assuming chains have converged
results.car.logit2 <- coda.samples(results.car.logit2,
                                  variable.names=c("clm.rep","beta0",
                                                   "beta.veh_value",
                                                   "beta.exposure" ,"beta.veh_age",
                                                   "beta.gender.m",
                                                   "beta.body.convt",
                                                   "beta.body.coupe",
                                                   "beta.body.hback"  ,
                                                   "beta.body.hdtop" ,
                                                   "beta.body.mcara" ,
                                                   "beta.body.mibus",
                                                   "beta.body.panvn",
                                                   "beta.body.rdstr"  ,
                                                   "beta.body.sedan"  ,
                                                   "beta.body.stnwg"  ,
                                                   "beta.body.truck",
                                                   "beta.body.ute"  ,
                                                   "beta.area.B"  ,
                                                   "beta.area.C" ,
                                                   "beta.area.D" ,
                                                   "beta.area.E" ,
                                                   "beta.area.F"  ,
                                                   "beta.agecat.2",
                                                   "beta.agecat.3",
                                                   "beta.agecat.4"  ,
                                                   "beta.agecat.5"  ,
                                                   "beta.agecat.6"),
                                  n.iter=3000)

# Summary 

```
Model string
```{r}
car.logit.model <- "model {
 beta.mu.0   <- 0
 beta.tau.0  <- 1/(log(15)^2)
 beta.mu <- 0
 beta.tau <- 1/(log(5)/2)^2
 # prior
 beta0       ~ dnorm(beta.mu.0,beta.tau.0)
 beta.veh_value   ~ dnorm(beta.mu,beta.tau)
 beta.exposure ~ dnorm(beta.mu,beta.tau)
 beta.veh_age    ~ dnorm(beta.mu,beta.tau)
 beta.gender ~ dnorm(beta.mu,beta.tau)
 for (i in 1:length(body[1,])){
     beta.body[i] ~ dnorm(beta.mu,beta.tau)
 }
 for (i in 1:length(agecat[1,])){
     beta.agecat[i] ~ dnorm(beta.mu,beta.tau)
 }
 for (i in 1:length(area[1,])){
     beta.area[i] ~ dnorm(beta.mu,beta.tau)
 }
 
 #Likelihood
 for(i in 1:n) {
   logit(mu[i])  <- beta0+beta.veh_value*veh_value[i] +
               beta.exposure*exposure[i] + beta.veh_age*veh_age[i] +
               beta.gender*gender[i] +
               sum(beta.body%*%body[i,]) +
               sum(beta.agecat%*%agecat[i,]) +
               sum(beta.area%*%area[i,])

   clm[i] ~ dbern(mu[i])
 } 
}"
```

```{r}
# Run JAGS to the completion of the "adaption" stage 
results.car.logit <- jags.model(file=textConnection(car.logit.model), 
                                   data=car.logit.data,
                                   n.chains=3)

# Burn-in of 10000 iterations
update(results.car.logit, n.iter=1000)

# Longer run for making inferences, assuming chains have converged
results.car.logit <- coda.samples(results.car.logit,
                                  variable.names=c("beta0","beta.veh_value",
                                                   "beta.exposure","beta.veh_age",
                                                   "beta.gender","beta.body",
                                                   "beta.agecat","beta.area"), 
                                  n.iter=1000)

# Summary 
summary(results.car.logit)
```

```{r}

#Interpretation of parameter values
#Joining all the chains in one data.frame
results.car.logit.output <- 
do.call(rbind.data.frame, results.car.logit)
#interpretation
cat("E[beta_LightMed] is",
mean(results.car.logit.output$`beta.agecat[1]`,3),"\n")

cat("E[beta_LightMed] is",
mean(results.car.logit.output$`beta.agecat[2]`,3),"\n")

cat("E[beta_LightMed] is",
mean(results.car.logit.output$`beta.agecat[3]`,3))

#... similarly for the other colours
```
```{r}
#interpretation
ilogit=function(x){ 1/(1+exp(-x))} #Inverse logistic function
cat("E[ilogit(beta0)] is",round(mean(ilogit(results.car.logit.output$beta0)),3),"\n")

```

```{r}
cat("E[ilogit(beta0+beta1)]/E[ilogit(beta0)] is",
round(mean(ilogit(results.beetles.output$beta0
                  +results.beetles.output$beta1))/
mean(ilogit(results.beetles.output$beta0)),3),"\n")
```



### Multiple regression in INLA
The logistic regression model using the required covariates was implemented in INLA. In previous part, we have standerdise the non-categorical covariates so that the mean is 1 and standered deviation is $1$ for each non-categorical covariate. For categorical covariates, INLA will automatically create $k-1$ indicators, where $k$ is the number of catogories for certain covariate. The link function is chosen to be the logit function in our model.

The results are shown below. The mean of the regression coefficients can be found in the first column of the summary results.
```{r}
#Priors for the regression coefficients.
prior.beta.logit <- list(mean.intercept = 0, prec.intercept =  0.31,
                    mean =0, 
                   prec = list(veh_value=5,exposure=6,
                               veh_body=0.3,veh_age=21,
                               gender=1,area=13.7,agecat=4.5))

#Fitting the model in INLA
#"control.fixed=prior.beta" sets regression coeff. priors.
results.car.logit.I <- inla(formula = clm ~ veh_value+exposure+veh_body+
               veh_age+gender+area+agecat, family="binomial",Ntrials=1,
             control.family=list(link="logit"),
data=car.inla.data, control.fixed=prior.beta.logit,
control.predictor = list(compute = TRUE,link=1),
control.compute=list(config=TRUE))
summary(results.car.logit.I)

```

As we created the reference group to be veh_body=BUS, gender=F, area=1,agecat=1, veh_age=1, the intercept $\beta_0$ reflects the scaled log odds ratio of this reference group. We can compute the mean of $p$ of the reference group, which is `r ilogit(-1.351)`. Hence, for the reference group, the probability of a claim is around $0.2$. For categorical covariate veh_body, the regression coefficient for each group is negative, indicating that all other vehicle categories have the probability of a claim lower than the BUS, and thus BUS is the one that most probable to have a claim. In addition, we see the regression coefficient for motorized caravan is the smallest among all the groups, which indicates that when other factors remain the same, motorized caravan is most likely to have a claim (apart from BUS). Similarly, we found the convertible vehicle is the least likely to have a claim, as the regression coefficient is the smallest among all the vehicle categories. For the covariate veh_age, we observe a increase trend in the regression coefficients. Therefore, we may believe that as the vehicle get older, the probability of a claim decreases. For the covariate gender, the regression coefficient is $-0.019$ for female. After taking the exponential, we can say the female have roughly $0.02$ less chance to claim than male. For covariate area, the regression coefficients for area B and F are positive, showing higher probabilities of a claim compared with the area A. The regression coefficients for area D and E are negative, showing lower probabilities of a claim compared with the area A. For the covariate agecat, we see the younger groups of people seem to have a larger probability to claim. 

For the non-categorical variable, we need to transfer the coefficients back to the original scale to better interpret the data. The transformed values are shown below. For the vehicle value, we expect $1.82$ times increase of the log odds ratio in every unit increase on the veh_value. Similarly, we expect $0.63$ times increase of the log odds ratio in every unit increase on the exposure. 

```{r}
cat("Regression coefficient for veh_value after transformation to the original scale: \n")
results.car.logit.I$summary.fixed$mean[2] * sd(dataCar$veh_value)+mean(dataCar$veh_value)

cat("Regression coefficient for exposure after transformation to the original scale: \n")
results.car.logit.I$summary.fixed$mean[3] * sd(dataCar$exposure)+mean(dataCar$exposure)
```

Now, we can compute the posterior mean of the model parameter ($p$) in Bernoulli distribution across different groups.

```{r}
fittedvaluesm.I <- results.car.logit.I$summary.fitted.values$mean
res.A <- car.data.scl %>% mutate(prob = ilogit(fittedvaluesm.I))
```

This is the posterior means of $p$ for different vehicle bodies. We see BUS has the highest claim probability while the convertible vehicle has the least probability to claim. Basically, we can get similar conclusion as the discussion in the previous part where the regression coefficients were discussed.
```{r}
res.A %>% 
  group_by(veh_body) %>%
  summarise(p.mu=mean(prob))
```

Female seems to have a slightly higher probability to claim. The difference is not significant though.
```{r}
res.A %>% 
  group_by(gender) %>%
  summarise(p.mu=mean(prob))
```
The oldest group of vehicle tends to be less likely to have a claim.
```{r}
res.A %>% 
  group_by(veh_age) %>%
  summarise(p.mu=mean(prob))
```

The younger groups of people tends to have a higher probability to claim
```{r}
res.A %>% 
  group_by(agecat) %>%
  summarise(p.mu=mean(prob))
```

Area F is the area where the probaility of a claim is the largest across different area. Area D is where the probaility of a claim is the smallest.
```{r}
res.A %>% 
  group_by(area) %>%
  summarise(p.mu=mean(prob))
```

```{r}
n <- nrow(car.data)
body.dum <- dummy(car.data.scl$veh_body)
agecat.dum <- dummy(car.data.scl$agecat)
gen.dum <- dummy(car.data.scl$gender)
area.dum <- dummy(car.data.scl$area)
newdata <- 
fittedvaluesm <- param.means[1]+param.means[2]*car.inla.data
```



```{r}

#Create new rows in the dataset for these widths,
#for all 4 colours, with the response Satellites set to NA
newdata <- car.inla.data %>%
  mutate(clm=rep(NA,len=nrow(car.inla.data)))
#Join the new rows with the original dataframe,
#and include the centered width covariate
newdata=rbind(newdata,car.inla.data)

#whenever we use a model with link function that is not the identity
#and we want to compute the posterior marginal and mean of mu_i
#and not eta_i,we need to set link=1 in control.predictor
m3.I <- inla(formula = clm ~ veh_value+exposure+veh_body+
               veh_age+gender+area+agecat, family="binomial",Ntrials=1,
             control.family=list(link="logit"),
data=newdata, control.fixed=prior.beta,
control.predictor = list(compute = TRUE,link=1),
control.compute=list(config=TRUE))

```


Explanation (min 300 characters in your own words, otherwise -5 marks
for insufficient explanation):


**b)[10 marks] Fit a Bayesian Poisson regression model on numclaims as
response with**

-   **log link function,**

-   **using veh_value, exposure, veh_body, veh_age, gender, area, and
    agecat as covariates.**

**Center and scale the non-categorical covariates.**

**Choose your own prior distributions (do not use default priors), and
explain the rationale your prior choices, and ensure that the posterior
is not too sensitive to your prior choice [Hint: look at the induced
prior on the linear predictor and the response.]**

**Compute the posterior means of the model parameters, and discuss the
results.**

We adopt a similar strategy for choosing priors as in part (a). However, here we look at the probability of each group instead of the odds ratio.
```{r}
# dataset
car.inla2.data <- car.data.scl %>% 
  filter(clm==1)%>%
  select(veh_value, exposure,veh_body, 
         veh_age, gender, area, agecat, numclaims)

mu.body <- c()
for (i in 1:13){
  body <- unique(car.inla2.data$veh_body)[i]
  df.body <- car.inla2.data %>% filter(veh_body %in% c(body)) 
  mu.body[i] <- mean(df.body$numclaims)
}
body.ratio <- max(mu.body)/min(mu.body)
body.ratio 

mu.gender <- c()
df.m <- car.inla2.data %>% filter(gender %in% c("M"))
df.f <- car.inla2.data %>% filter(gender %in% c("F"))
mu.gender[1] <- mean(df.m$numclaims)
mu.gender[2] <- mean(df.f$numclaims)
gender.ratio <- max(mu.gender)/min(mu.gender)
gender.ratio

mu.area <- c()
for (i in 1:6){
  a <- unique(car.inla2.data$area)[i]
  df.area <- car.inla2.data %>% filter(area %in% c(a)) 
  mu.area[i] <- mean(df.area$numclaims)
}
area.ratio <- max(mu.area)/min(mu.area)
area.ratio

mu.agecat <- c()
for (i in 1:6){
  age <- unique(car.inla2.data$agecat)[i]
  df.agecat <- car.inla2.data %>% filter(agecat %in% c(age)) 
  mu.agecat[i] <- mean(df.agecat$numclaims)
}
agecat.ratio <- max(mu.agecat)/min(mu.agecat)
agecat.ratio


mu.v_age <- c()
for (i in 1:4){
  v_age <- unique(car.inla2.data$veh_age)[i]
  df.v_age <- car.inla2.data %>% filter(veh_age %in% c(v_age)) 
  mu.v_age[i] <- mean(df.v_age$numclaims)
}
v_age.ratio <- max(mu.v_age)/min(mu.v_age)
v_age.ratio
```


```{r}

#Priors for the regression coefficients.
prior.beta.log.I <- list(mean.intercept = 0, prec.intercept =  0.5,
                    mean =0, 
                   prec = 1)
#Fitting the model in INLA
#"control.fixed=prior.beta" sets regression coeff. priors.
results.car.log.I <- inla(formula = numclaims ~ veh_value+exposure+veh_body+
               veh_age+gender+area+agecat, family="poisson",
             control.family=list(link="log"),
data=car.inla2.data, control.fixed=prior.beta.log,
control.predictor = list(compute = TRUE,link=1),
control.compute=list(config=TRUE))
summary(results.car.log.I)
```

Explanation (min 300 characters in your own words, otherwise -5 marks
for insufficient explanation):

We fit the regression model in INLA using log as the link function. For the regression coefficient corresponding to veh_value, $\beta_1$, we chose a normal prior $\mathcal{N}(0,\log2/27.2)$, as we believe an extreme case can have a mean at most $4$ times the mean of a typical number of claims. Similarly for the other three non-categorical regression coefficients, the priors are set to be $\mathcal{N}(0,\log4/1.83)$ for $beta_2$ that corresponds to exposure, $\mathcal{N}(0,1.24)$ for $\beta_3$ that corresponds to veh_age. 

**c)[10 marks]** **Fit a zero-inflated Bayesian Poisson regression model
(<https://en.wikipedia.org/wiki/Zero-inflated_model>) on**

-   **numclaims as response,**

-   **with log link function,**

-   **using veh_value, exposure, veh_body, veh_age, gender, area, and
    agecat as covariates.**

**Center and scale the non-categorical covariates.**

**Choose your own prior distributions (do not use default priors), and
explain the rationale your prior choices, and ensure that the posterior
is not too sensitive to your prior choice [Hint: look at the induced
prior on the linear predictor and the response.]**

**Compute the posterior means of the model parameters, and discuss the
results.**

```{r}
car.poi.data.scl <- dataCar %>% 
  select(veh_value, exposure,
         veh_body, veh_age, gender, 
         area, agecat, numclaims) %>%
  mutate(veh_value=scale(veh_value), exposure=scale(exposure),
         veh_age=scale(veh_age))

#Priors for the regression coefficients.
prior.beta <- list(mean.intercept = 0, prec.intercept =  3,
                    mean = 0, prec = 3)
#Fitting the model in INLA
#"control.fixed=prior.beta" sets regression coeff. priors.
results.car.poi <- inla(formula = clm ~ veh_value+exposure+veh_body+
               veh_age+gender+area+agecat, family="zeroinflatedpoisson1",
             control.family=list(link="log"),
data=car.inla.data, control.fixed=prior.beta,
control.predictor = list(compute = TRUE,link=1),
control.compute=list(config=TRUE))
summary(results.car.poi)
```

Explanation (min 300 characters in your own words, otherwise -5 marks
for insufficient explanation):

**d)[10 marks] Fit a new model on numclaims in terms of the same
covariates to improve on the models in part b) or part c) by considering
interactions between covariates, as well as random effects. Describe
your new model and justify your choices.**

**Choose your own prior distributions (do not use default priors), and
explain the rationale your prior choices, and ensure that the posterior
is not too sensitive to your prior choice [Hint: look at the induced
prior on the linear predictor and the response.]**

**Compute the posterior means of the model parameters, and discuss the
results.**

```{r}

```

Explanation (min 300 characters in your own words, otherwise -5 marks
for insufficient explanation):

**e)[10 marks] Perform posterior predictive model checks for your models
b, c, d (i.e. using replicates).**

**As test functions, use the number of rows in the dataset with
numclaims equal 0, 1, 2, 3, and 4 (5 test functions).**

**Compute the RMSE values for predicting numclaims based on all 3
models.**

**Discuss the results.**

```{r}
```

Explanation (min 300 characters in your own words, otherwise -5 marks
for insufficient explanation):

![](barcelona.jpg)

**Problem 2 - Barcelona study**

**In this problem, we will use a dataset from the CitieS-Health project
that provides insight into the impact of air pollution on humans. It is
comprised of data collected in Barcelona, Spain, and examines various
environmental variables, such as air pollution levels, and their effects
on mental health and wellbeing. In addition to environmental factors,
this dataset also captures self-reported survey data on mental health,
physical activity, diet habits, and more. From performance in a Stroop
test (a type of psychological test evaluating attention capacity and
processing speed) to information on total noise exposure at 55 dB - this
dataset contains interesting information to understand the link between
air pollution and human health.**

**We start by loading the dataset.**

```{r}
 study<-read.csv("Barcelona.csv")
 head(study)
```

**Descriptions of some of the covariates:**

| **Column name**                     | **Description**                                                                                    |
|-------------------------|-----------------------------------------------|
| **Person_ID**                       | ID of person filling out the survey (integer). Multiple rows for most persons, at different dates. |
| **date_all**                        | Date of the survey. (Date)                                                                         |
| **year**                            | Year of the survey. (Integer)                                                                      |
| **month**                           | Month of the survey. (Integer)                                                                     |
| **day**                             | Day of the survey. (Integer)                                                                       |
| **dayoftheweek**                    | Day of the week of the survey. (Integer)                                                           |
| **hour**                            | Hour of the survey. (Integer)                                                                      |
| **sadness**                         | Sadness score. (Integer)                                                                           |
| **wellbeing**                       | Self-reported survey responses regarding wellbeing. (Integer)                                      |
| **energy**                          | Self-reported survey responses regarding energy levels. (Integer)                                  |
| **stress**                          | Self-reported survey responses regarding stress levels. (Integer)                                  |
| **sleep**                           | Self-reported survey responses regarding sleep quality. (Integer)                                  |
| **hours_out**                       | Self-reported survey responses regarding time spent outdoors. (Integer)                            |
| **computer_use**                    | Self-reported survey responses regarding computer use. (Yes/No)                                    |
| **on_a\_diet**                      | Self-reported survey responses regarding diet. (Yes/No)                                            |
| **alcohol**                         | Self-reported survey responses regarding alcohol consumption. (Yes/No)                             |
| **drugs**                           | Self-reported survey responses regarding drug use. (Yes/No)                                        |
| **sick**                            | Self-reported survey responses regarding illness. (Yes/No)                                         |
| **other_factors**                   | Self-reported survey responses regarding other factors. (Yes/No)                                   |
| **stroop_test_performance**         | Performance in the Stroop test. (Float)                                                            |
| **no2bcn_24h**                      | Nitrogen dioxide (NO2) levels in Barcelona over 24 hours. (Float)                                  |
| **no2bcn_12h**                      | Nitrogen dioxide (NO2) levels in Barcelona over 12 hours. (Float)                                  |
| **no2gps_24h**                      | Nitrogen dioxide (NO2) levels in GPS locations over 24 hours. (Float)                              |
| **no2gps_12h**                      | Nitrogen dioxide (NO2) levels in GPS locations over 12 hours. (Float)                              |
| **no2bcn_12h_x30**                  | Nitrogen dioxide (NO2) levels in Barcelona over 12 hours multiplied by 30. (Float)                 |
| **no2bcn_24h_x30**                  | Nitrogen dioxide (NO2) levels in Barcelona over 24 hours multiplied by 30. (Float)                 |
| **no2gps_12h_x30**                  | Nitrogen dioxide (NO2) levels in GPS locations over 12 hours multiplied by 30. (Float)             |
| **no2gps_24h_x30**                  | Nitrogen dioxide (NO2) levels in GPS locations over 24 hours multiplied by 30. (Float)             |
| **min_gps**                         | Minimum GPS location. (Float)                                                                      |
| **district**                        | District of Barcelona where the survey was conducted. (String)                                     |
| **education**                       | Educational level of the participant. (String)                                                     |
| **maxwindspeed_12h**                | Maximum wind speed over 12 hours. (Float)                                                          |
| **access_greenbluespaces_300mbuff** | Access to green and blue spaces within a 300m buffer. (Yes/No)                                     |
| **microgram3**                      | Micrograms per cubic meter of pollutants. (Float)                                                  |
| **age_yrs**                         | Age of the participant in years. (Integer)                                                         |
| **yearbirth**                       | Year of birth of the participant. (Integer)                                                        |
| **smoke**                           | Self-reported survey responses regarding smoking status. (Yes/No)                                  |
| **gender**                          | Gender of the participant. (Woman/Man)                                                             |
| **hour_gps**                        | Hour of the GPS location. (Integer)                                                                |
| **pm25bcn**                         | Particulate matter (PM2.5) levels in Barcelona. (Float)                                            |
| **BCmicrog**                        | Black carbon (BC) levels in micrograms. (Float)                                                    |
| **sec_noise55_day**                 | Seconds of noise over 55 minutes in a day. (Integer)                                               |
| **sec_noise65_day**                 | Seconds of noise over 65 minutes in a day. (Integer)                                               |
| **tmean_24h**                       | Mean temperature over 24 hours. (Float)                                                            |
| **tmean_12h**                       | Mean temperature over 12 hours. (Float)                                                            |
| **humi_24h**                        | Humidity over 24 hours. (Float)                                                                    |
| **humi_12h**                        | Humidity over 12 hours. (Float)                                                                    |
| **pressure_24h**                    | Pressure over 24 hours. (Float)                                                                    |
| **pressure_12h**                    | Pressure over 12 hours. (Float)                                                                    |
| **precip_24h**                      | Precipitation over 24 hours. (Float)                                                               |
| **precip_12h**                      | Precipitation over 12 hours. (Float)                                                               |
| **precip_12h_binary**               | Binary value for precipitation over 12 hours. (Integer)                                            |
| **precip_24h_binary**               | Binary value for precipitation over 24 hours. (Integer)                                            |
| **maxwindspeed_24h**                | Maximum wind speed over 24 hours. (Float)                                                          |

**You can use either JAGS, Stan, or INLA for this question.**

**a)[10 marks] Fit a Bayesian linear regression model**

-   **on the logarithm of stroop_test_performance as response,**

-   **using the following covariates: gender, on_a\_diet, alcohol,
    drugs, sick, other_factors, educational, smoke, no2gps_24h,
    maxwindspeed_24h, precip_24h, sec_noise55_day,
    access_greenbluespaces_300mbuff, age_yrs, tmean_24h (you can use
    categorical covariates by converting integers to factors if
    appropriate).**

**Center and scale the non-categorical covariates.**

**Choose your own prior distributions (do not use default priors), and
explain the rationale your prior choices, and ensure that the posterior
is not too sensitive to your prior choice [Hint: look at the induced
prior on the response.]**

**Compute the posterior means of the model parameters, and interpret
their meaning.**

```{r}

```

Explanation (min 300 characters in your own words, otherwise -5 marks
for insufficient explanation):

**b)[10 marks] Fit a Bayesian Poisson GLM**

-   **for sadness as response,**

-   **log link function,**

-   **using the following covariates: gender, on_a\_diet, alcohol,
    drugs, sick, other_factors, educational, smoke, no2gps_24h,
    maxwindspeed_24h, precip_24h, sec_noise55_day,
    access_greenbluespaces_300mbuff, age_yrs, tmean_24h (you can use
    categorical covariates by converting integers to factors if
    appropriate).**

**Center and scale the non-categorical covariates.**

**Choose your own prior distributions (do not use default priors), and
explain the rationale your prior choices, and ensure that the posterior
is not too sensitive to your prior choice [Hint: look at the induced
prior on the response.]**

**Compute the posterior means of the model parameters, and interpret
their meaning.**

```{r}

```

Explanation (min 300 characters in your own words, otherwise -5 marks
for insufficient explanation):

**c)[10 marks] Incorporate Person_ID as a random effects into the models
a.) and b.).**

**Choose your own prior distributions for this random effect (do not use
default priors).**

**Compare the posterior means of the parameter values with a) and b).**

**Discuss the changes that happened due to using random effects.**

```{r}

```

Explanation (min 300 characters in your own words, otherwise -5 marks
for insufficient explanation):

**d)[10 marks] Do posterior predictive checks (i.e. using replicates)
for the sadness score for your models with or without random effects.
Explain the choice of test functions that you used.**

**Compute the posterior means of the response variable using the
original covariates, and use this to compute the RMSE values for both
models (i.e. with, or without random effects).**

**Discuss the results.**

```{r}

```

Explanation (min 300 characters in your own words, otherwise -5 marks
for insufficient explanation):

**e)[10 marks]**

**Plot the posterior predictive distributions for
stroop_test_performance and sadness for the random effect models in part
c) for the following new person in the dataset:**

**Person_ID=286, gender="Woman", on_a\_diet="Yes", alcohol="No",
drugs="No", sick="No", other_factors="No", education="University",
smoke="Yes", no2gps_24h=80, maxwindspeed_24h=10, precip_24h=50,
sec_noise55_day=10000, access_greenbluespaces_300mbuff="Yes",
age_yrs=40, tmean_24h=25**

**In the case of stroop_test_performance, plot the estimated density,
while for sadness, plot a histogram.**

**Compute the posterior predictive mean, and standard deviation.**

**Discuss the results.**

```{r}

```

Explanation (min 300 characters in your own words, otherwise -5 marks
for insufficient explanation):
